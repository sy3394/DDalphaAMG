/*          
 * Copyright (C) 2016, Matthias Rottmann, Artur Strebel, Simon Heybrock, Simone Bacchio, Bjoern Leder.
 * 
 * This file is part of the DDalphaAMG solver library.
 * 
 * The DDalphaAMG solver library is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 * 
 * The DDalphaAMG solver library is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 * 
 * 
 * You should have received a copy of the GNU General Public License
 * along with the DDalphaAMG solver library. If not, see http://www.gnu.org/licenses/.
 * checked:11/30/2019
 * changed from sbacchio
 */

#include "main.h"

static void vector_PRECISION_copy_fab( vector_PRECISION *z, vector_PRECISION *x, int vec_ind, int length, int dir, int start, int end );
  
void setup_fabulous_PRECISION( int iter, int restart, int v_type, PRECISION tol,
			       fabulous_PRECISION_struct *fab, int nrhs, int dim, operator_PRECISION_struct *op, void (*eval_op)(),
			       gmres_PRECISION_struct *p, level_struct *l, struct Thread *threading ) {
  printf0("fab set: %d %d %d %g\n",nrhs,dim,l->depth, tol);
  //----- Set fabulous structure
  fab->nrhs = nrhs;
  vector_PRECISION *X = &(fab->X) , *B = &(fab->B), *B0 = &(fab->B0), *X0 = &(fab->X0), *C0 = &(fab->C0);
  // The following fields are used only internally; will be unnecessary if fabulous can handle _ORINARY properly!!!!
  vector_PRECISION_init(X);
  vector_PRECISION_init(B);
  vector_PRECISION_alloc( X, _INNER, nrhs, l, threading ); X->num_vect_now = nrhs;
  vector_PRECISION_alloc( B, _INNER, nrhs, l, threading ); B->num_vect_now = nrhs;
  // The following fields are used to communicate the result to the outside
  vector_PRECISION_alloc( &(p->b), v_type, nrhs, l, no_threading );
  vector_PRECISION_alloc( &(p->x), v_type, nrhs, l, no_threading );
  p->v_start = 0;
  p->v_end = l->inner_vector_size;
  // The following fields are used in mvp_PRECISION for temporay storage
  vector_PRECISION_init(X0);
  vector_PRECISION_init(B0);
  vector_PRECISION_init(C0);
  vector_PRECISION_alloc( X0, _INNER, nrhs, l, threading ); X0->num_vect_now = nrhs; X0->layout = _NVEC_OUTER;
  vector_PRECISION_alloc( B0, _INNER, nrhs, l, threading ); B0->num_vect_now = nrhs; B0->layout = _NVEC_OUTER;
  vector_PRECISION_alloc( C0, _INNER, nrhs, l, threading ); C0->num_vect_now = nrhs; C0->layout = _NVEC_OUTER;
  if ( X->size != dim )
    error0("set_fabulous_struct_PRECISION: assumptions are not met\n");
  
  fab->dim = dim; fab->ldb = dim; fab->ldx = dim;
  fab->op = op;
  fab->apply_op_PRECISION = eval_op;
  fab->l = l;
  fab->threading = threading;//needed?????                                                                                                                                 
  if ( g.fab_double.k > 0 )
    MALLOC( (PRECISION *) fab->eigvals, PRECISION, g.fab_double.k );

  //----- Set fabulous handle
  fab->handle = fabulous_create(FABULOUS_COMPLEX_PRECISION, fab->dim, (void *) fab);
  if ( fab->handle == NULL )
    error0("fabulous handle has not been created!\n");

  // Set callback:
  fabulous_set_mvp(&mvp_double, fab->handle);
  fabulous_set_dot_product(&dot_product_double, fab->handle);
  
  // Setup parameters:
  double tolerance[1] = { (double) tol };
  fabulous_set_parameters(
			  //g.restart*g.max_restart*g.num_rhs_vect*l->num_lattice_sites, // Maximum number of Matrix X Vector product ?????
			  iter,
			  restart,    // maximum size of base before restart
			  tolerance, // maximum value for the Backward Error to consider the solution has converged 
			  1,         /* size of tolerance array */
			  fab->handle  /* handle as returned by fabulous_init */
			  );
  fabulous_set_ortho_process(g.f_orthoscheme, g.f_orthotype, 2, fab->handle); // #iter for iter GS is hard-coded for the moment!!!!

  fabulous_set_advanced_parameters( 50,
                                     0,
                                     10,
                                     0,
                                     fab->handle);

}

void fabulous_PRECISION_free( fabulous_PRECISION_struct *fab, gmres_PRECISION_struct *p, level_struct *l, struct Thread *threading ) {

  vector_PRECISION_free(&(p->x), l, threading);
  vector_PRECISION_free(&(p->b), l, threading);
  vector_PRECISION_free(&(fab->X), l, threading);
  vector_PRECISION_free(&(fab->B), l, threading);
  vector_PRECISION_free(&(fab->X0), l, threading);
  vector_PRECISION_free(&(fab->B0), l, threading);
  vector_PRECISION_free(&(fab->C0), l, threading);
  if ( g.fab_double.k > 0 )
     PUBLIC_FREE( fab->eigvals, PRECISION, g.fab_double.k );
  
  fabulous_destroy(fab->handle);
}

// B= A*X: Matrix x BlockOfVector product CALLBACK: vectors need to be in _NVEC_INNER
int64_t mvp_PRECISION(  void *user_env, int N,
			const void *p_alpha, const void *XX, int ldx,
			const void *p_beta, void *BB, int ldb) {

  fabulous_PRECISION_struct *fab = user_env;
      printf0("mvp %d: %d vs %d; %d %d %d\n", g.my_rank, N, fab->B0.num_vect, ldx, ldb, fab->B0.size );fflush(stdout);
  //  START_UNTHREADED_FUNCTION(fab.threading)
  int n = fab->B0.num_vect;
  const complex_PRECISION alpha = *(const complex_PRECISION*) p_alpha, beta = *(const complex_PRECISION*) p_beta;
  complex_PRECISION alphas[n], betas[n];
  for ( int i=0; i<n; i++ ) {alphas[i] = alpha; betas[i] = beta; }
  vector_PRECISION B, X, B0 = fab->B0, X0 = fab->X0, C0 = fab->C0;
  vector_PRECISION_duplicate( &B, &B0, 0, fab->l ); B.num_vect = N; B.num_vect_now = N; B.size = ldb;
  vector_PRECISION_duplicate( &X, &X0, 0, fab->l ); X.num_vect = N; X.num_vect_now = N; X.size = ldx;
  B.vector_buffer = BB;
  X.vector_buffer = (const buffer_PRECISION) XX;
  if ( fab->dim != X.size || N > X.num_vect )
    error0("Fabulous matrix vector product callback: assumptions are not met\n");
  vector_PRECISION_copy_fab( &B0, &B, 0, N, 1, 0, fab->dim );
  vector_PRECISION_copy_fab( &X0, &X, 0, N, 1, 0, fab->dim );
  
  // may need to write a new dirac op function for column major order!!!!
  vector_PRECISION_change_layout( &X0, &X0, _NVEC_INNER, no_threading );
  vector_PRECISION_change_layout( &B0, &B0, _NVEC_INNER, no_threading );
  vector_PRECISION_scale( &B0, &B0, betas, 0, 0, fab->dim, fab->l );
  fab->apply_op_PRECISION( &C0, &X0, fab->op, fab->l, no_threading );
  vector_PRECISION_saxpy( &B0, &B0, &C0, alphas, 0, 1, 0, fab->dim, fab->l );
  X.layout = _NVEC_OUTER;
  vector_PRECISION_change_layout( &B0, &B0, _NVEC_OUTER, no_threading );

  vector_PRECISION_copy_fab( &B, &B0, 0, N, -1, 0, fab->dim );
  //  END_UNTHREADED_FUNCTION(fab.threading)
printf0("mvp2 %d: %d vs %d; %d %d %d\n", g.my_rank, N, fab->B0.num_vect, ldx, ldb, fab->B0.size );fflush(stdout);

  return sizeof(PRECISION)/4*N*ldx*ldx;//this is actually wrong!!!!!;
}
// C = A^{H} * B: Dot product CALLBACK: vectors need to be in _NVEC_INNER 
int64_t dot_product_PRECISION(void *user_env,
			      int M, int N,
			      const void *A_, int lda,
			      const void *B_, int ldb,
			      void *C_, int ldc) {

  fabulous_PRECISION_struct *fab = user_env;
  level_struct *l = fab->l;
  struct Thread *threading = fab->threading;
  buffer_PRECISION A, B, C;
  A = (const buffer_PRECISION) A_;
  B = (const buffer_PRECISION) B_;
  C = C_;

  int i, j, k, s;
  complex_PRECISION global_alpha[ldc*N];
  printf0("dot %d %d, %d %d %d\n", M,N,lda,ldb,ldc);fflush(stdout);
  for ( s=0; s<ldc*N; s++ ) C[s] = 0; 
  for ( s=0; s<ldc*N; s++ ) global_alpha[s] = 0;//printf0("dot0 %d %d %d %d %d %d\n", M, N, lda, ldb,ldc, fab->dim);
#if 0
  int thread_start;
  int thread_end;
  compute_core_start_end_custom(0, fab->dim, &thread_start, &thread_end, l, threading, l->num_lattice_site_var );

  for( i=thread_start; i<thread_end; i++)
#endif
    for ( j=0; j<M; j++ )
      for (k=0; k<N; k++ )
	for ( s=0; s<fab->dim; s++ ) C[k*ldc+j] += conj_PRECISION(A[j*lda+s])*B[k*ldb+s];
  //for ( s=thread_start; s<thread_end; s++ ) C[k*ldc+j] += conj_PRECISION(A[j*lda+s])*B[k*ldb+s];

  /////////////// communication -----------------------------------
#if 0 // Assume: the fabulous solver is called out of OpenMP region
  // sum over cores
  START_NO_HYPERTHREADS(threading)
    for ( s=0; s<M*N; s++ ) ((complex_PRECISION *)threading->workspace)[threading->core*ldc*N+s] = C[ldc*(s/M)+s%M];
  END_NO_HYPERTHREADS(threading)
  // master sums up all results
  SYNC_CORES(threading)
  START_MASTER(threading)
  for( i=1; i<threading->n_core; i++)
    for ( s=0; s<M*N; s++ ) ((complex_PRECISION *)threading->workspace)[s] += ((complex_PRECISION *)threading->workspace)[i*M*N+s];
  END_MASTER(threading)
  SYNC_MASTER_TO_ALL(threading)
    for ( s=0; s<M*N; s++ )  C[ldc*(s/M)+s%M] = ((complex_PRECISION *)threading->workspace)[s];
#endif  
  if ( g.num_processes > 1 ) {
    START_MASTER(threading)
    PROF_PRECISION_START( _ALLR );
    MPI_Allreduce( C, global_alpha, ldc*N, MPI_COMPLEX_PRECISION, MPI_SUM, (l->depth==0)?g.comm_cart:l->gs_PRECISION.level_comm );
    PROF_PRECISION_STOP( _ALLR, 1 );
    for ( s=0; s<M*N; s++ ) ((complex_PRECISION *)threading->workspace)[s] = global_alpha[ldc*(s/M)+s%M];
    END_MASTER(threading)
    // all threads need the result of the norm
    SYNC_MASTER_TO_ALL(threading)
    for ( s=0; s<M*N; s++ ) C[ldc*(s/M)+s%M] = ((complex_PRECISION *)threading->workspace)[s];
    //        for ( s=0; s<ldc*N; s++ ) C[s] = global_alpha[s];
  }
  printf0("dot end\n");fflush(stdout);
  return 2L*N*M*lda;
}
 
// dir == 1: z[0:length] <-x[vec_ind:vec_ind+length]; dir==-1: z[vec_ind:vec_ind+length] <- x[0:length]
static void vector_PRECISION_copy_fab( vector_PRECISION *z, vector_PRECISION *x, int vec_ind, int length, int dir, int start, int end ) {

  int layout = x->layout;
  int i, j;
  if ( layout == _NVEC_INNER ) {
    if ( dir == 1 )
      for( i=start; i<end; i++)
	for( j=0; j<length; j++ ) z->vector_buffer[i*z->num_vect+j] = x->vector_buffer[i*x->num_vect+vec_ind+j];
    else
      for( i=start; i<end; i++)
	for( j=0; j<length; j++ ) z->vector_buffer[i*z->num_vect+vec_ind+j] = x->vector_buffer[i*x->num_vect+j];
  }
  else if ( layout == _NVEC_OUTER ) {
    if ( dir == 1 )
      for( j=0; j<length; j++ )
	for( i=start; i<end; i++) z->vector_buffer[j*z->size+i] = x->vector_buffer[(vec_ind+j)*x->size+i];
    else
      for( j=0; j<length; j++ )
	for( i=start; i<end; i++) z->vector_buffer[(vec_ind+j)*z->size+i] = x->vector_buffer[j*x->size+i];
  }
}
